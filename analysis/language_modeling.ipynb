{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "import random\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import sklearn_helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Read in our data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dims:\t (52751, 33)\n"
     ]
    }
   ],
   "source": [
    "data_path = '../data/clean_data_full.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "print(\"Data dims:\\t\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the reviews and number of ratings the user's have made..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews = df['review_blob'].values\n",
    "user_experience_level = df['user_experience'].values\n",
    "curr_reviews = df['review_blob'].values[:5000]\n",
    "curr_user_experience_level = df['user_experience'].values[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This beer is iconic because people like me in their 30s remember it from the Uncles drinking it when you were a kid. This is not a beer for beer snobs. Certainly America has come of age with beer - microbrews and the popularity of foreign beers. But...appreciate it for what it is - an old time classic thats making a bit of a comeback with the college set. Colder is better, draft bottles over cans. I have a pub close by that has it for $3.00 a 20 oz glass.   It has a decent flavor, very drinkable. Much more character than the generic beers from Budweiser. \n"
     ]
    }
   ],
   "source": [
    "print(reviews[12931])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from LanguageModel import Trigram_SB_LM\n",
    "import LanguageModelClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lm = Trigram_SB_LM\n",
    "lang_model_classifier = LanguageModelClassifier.LanguageModelClassifier(Trigram_SB_LM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model_cv(X, y, model, cv = 10, scoring = 'mean_squared_error'):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"    \n",
    "    scores = cross_val_score(model,\n",
    "                             X = X,\n",
    "                             y = y,\n",
    "                             scoring = scoring,\n",
    "                             cv = cv)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_vectorizer(ngram_range = (1,1),\n",
    "                   min_df = 3,\n",
    "                   sample_size = 10000,\n",
    "                   stop_words = None,\n",
    "                   lowercase = True,\n",
    "                   binary = False):\n",
    "\n",
    "    max_features = int(sample_size * features_prop) if max_features == None else max_features\n",
    "    \n",
    "    return CountVectorizer(analyzer='word',\n",
    "                           ngram_range = ngram_range,\n",
    "                           min_df = min_df,\n",
    "                           max_features = max_features,\n",
    "                           stop_words = stop_words,\n",
    "                           binary = binary,\n",
    "                           lowercase = lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime:\t 84.6095929146\n"
     ]
    }
   ],
   "source": [
    "## CV 2 with 10K obs ~98sec\n",
    "## CV 10 with 15K obs ~248sec\n",
    "## CV 10 with 25K obs ~407sec\n",
    "t0 = time()\n",
    "preds = fit_model_cv(curr_reviews, curr_user_experience_level, lang_model_classifier, cv = 10, scoring = 'f1_micro')\n",
    "print(\"runtime:\\t\", time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.36526946  0.39121756  0.45908184  0.416       0.498       0.516       0.33\n",
      "  0.36673347  0.4488978   0.42685371]\n",
      "0.421805383222\n",
      "0.00324540357479\n"
     ]
    }
   ],
   "source": [
    "print(preds)\n",
    "print(np.mean(preds))\n",
    "print(np.var(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for NB and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VECTORIZER_TOKEN_PATTERN = u\"(?u)\\\\b\\\\w+\\\\b\"\n",
    "ngram_vectorizer = CountVectorizer(ngram_range=(1,1),\\\n",
    "                                        min_df=1,\\\n",
    "                                        max_df=1.0,\\\n",
    "                                        lowercase=True,\\\n",
    "                                        analyzer=\"word\",\\\n",
    "                                        token_pattern=VECTORIZER_TOKEN_PATTERN)\n",
    "X = ngram_vectorizer.fit_transform(curr_reviews)\n",
    "y = curr_user_experience_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "built_data_set = sklearn_helpers.build_data_set(df, vectorizer = ngram_vectorizer, aspect_str = \"user_experience\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Multinomial_NB = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = fit_model_cv(built_data_set['X'], built_data_set['y'], Multinomial_NB, cv = 20, scoring = 'f1_micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.348710925192\n",
      "0.000444556067403\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(preds))\n",
    "print(np.var(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseline = LanguageModelClassifier.BaselineLanguageModel()\n",
    "preds = fit_model_cv(curr_reviews, curr_user_experience_level, baseline, cv = 10, scoring = 'f1_micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.21956088,  0.21956088,  0.21956088,  0.218     ,  0.218     ,\n",
       "        0.218     ,  0.218     ,  0.21843687,  0.21843687,  0.21843687])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseline.fit(curr_reviews, curr_user_experience_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Q2', 'Q2', 'Q2', 'Q2', 'Q2', 'Q2', 'Q2', 'Q2', 'Q2']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user_num_ratings'].quantile(q = [0.25, 0.5, 0.75]).values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# review[df.loc[(df['user_num_ratings'] > 75) & (df['user_num_ratings'] < 276), :]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "# print(\"Performing grid search...\")\n",
    "# print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "# print(\"parameters:\")\n",
    "# pprint(parameters)\n",
    "# t0 = time()\n",
    "# grid_search.fit(data.data, data.target)\n",
    "# print(\"done in %0.3fs\" % (time() - t0))\n",
    "# print()\n",
    "\n",
    "# print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "# print(\"Best parameters set:\")\n",
    "# best_parameters = grid_search.best_estimator_.get_params()\n",
    "# for param_name in sorted(parameters.keys()):\n",
    "#     print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
