{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "import random\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "## Classifiers\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "## Regression\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.dummy import DummyRegressor\n",
    "## Custom build_data_set helper\n",
    "import sklearn_helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Read in our data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dims:\t (52751, 33)\n"
     ]
    }
   ],
   "source": [
    "data_path = '../data/clean_data_full.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "print(\"Data dims:\\t\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_reader(train_path = data_path, n = 1000):\n",
    "    df = pd.read_csv(data_path)\n",
    "    return df.sample(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the reviews and number of ratings the user's have made..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "curr_df = data_reader(data_path, n = 30000)\n",
    "\n",
    "reviews = curr_df['review_blob'].values\n",
    "user_experience_level = curr_df['user_experience'].values\n",
    "# curr_reviews = curr_df['review_blob'].values\n",
    "# curr_user_experience_level = curr_df['user_experience'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bottle from may 2010. opaque black body and a thick mocha head. roasty, dark chocolate aroma and a bit of spiciness from the booze. amazing taste of dark chocolate with a slight spiciness from the booze. Finish is an amazing combo of bitterness and slight spice or pepper as advertised. the pepper just lingers in a not overwhelming way. i love this beer \n"
     ]
    }
   ],
   "source": [
    "print(reviews[12931])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model_cv(X, y, model, cv = 10, scoring = 'mean_squared_error'):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"    \n",
    "    scores = cross_val_score(model,\n",
    "                             X = X,\n",
    "                             y = y,\n",
    "                             scoring = scoring,\n",
    "                             cv = cv)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_vectorizer(ngram_range = (1,1),\n",
    "                   features_prop = 0.2,\n",
    "                   min_df=3,\n",
    "                   max_df=1.0,\n",
    "                   lowercase=True,\n",
    "                   analyzer=\"word\",\n",
    "                   token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\",\n",
    "                   binary = False):\n",
    "\n",
    "    max_features = int(sample_size * features_prop) if max_features == None else max_features\n",
    "    \n",
    "    return CountVectorizer(ngram_range=ngram_range,\n",
    "                           max_features=max_features,\n",
    "                           min_df=min_df,\n",
    "                           max_df=max_df,\n",
    "                           lowercase=lowercase,                           \n",
    "                           analyzer=analyzer,\n",
    "                           token_pattern=token_pattern,\n",
    "                           binary=binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from LanguageModel import Trigram_SB_LM, UnigramLM_Laplace\n",
    "import LanguageModelClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime:\t 443.94390893\n",
      "[ 0.44718427  0.44885038  0.46284572  0.46684439  0.452       0.463\n",
      "  0.44166667  0.45715238  0.44248083  0.46364243]\n",
      "0.454566706444\n",
      "7.85702508469e-05\n"
     ]
    }
   ],
   "source": [
    "## Unigram Laplace smoothing\n",
    "## -------------------------\n",
    "## =========================\n",
    "## CV 2 with 15K obs ~116sec :: score = 0.385, var = 0.0002\n",
    "## CV 10 with 15K obs ~229sec :: score = 0.3959, var = 0.0019\n",
    "## CV 10 with 30000 obs ~437sec :: score = 0.45, var = 0.000118\n",
    "Uni_lm = LanguageModelClassifier.LanguageModelClassifier(UnigramLM_Laplace)\n",
    "t0 = time()\n",
    "preds = fit_model_cv(reviews, user_experience_level, Uni_lm, cv = 10, scoring = 'accuracy')\n",
    "print(\"runtime:\\t\", time() - t0)\n",
    "print(preds)\n",
    "print(np.mean(preds))\n",
    "print(np.var(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime:\t 465.67603898\n",
      "[ 0.49350217  0.47850716  0.5164945   0.4925025   0.48833333  0.49133333\n",
      "  0.49633333  0.49649883  0.48149383  0.49499666]\n",
      "0.492999565989\n",
      "9.46820665664e-05\n"
     ]
    }
   ],
   "source": [
    "## Stupid back-off runs\n",
    "## -------------------------\n",
    "## =========================\n",
    "## CV 2 with 10K obs ~98sec\n",
    "## CV 10 with 15K obs ~248sec\n",
    "## CV 10 with 25K obs ~407sec\n",
    "## CV 2, with 20K obs ~487\n",
    "## CV 10 with 25K obs ~375, score 0.3383, var 0.00054\n",
    "## CV 10 with 40K obs ~ 596sec, 0.33score , 0.0004var \n",
    "## CV 10 with 30000 obs ~455 :: score = 0.494, var = 0.0000000118\n",
    "## CV 10 with 30000 obs ~455 :: score = 0.494, var = 0.00000918\n",
    "\n",
    "SB_lm = LanguageModelClassifier.LanguageModelClassifier(Trigram_SB_LM)\n",
    "t0 = time()\n",
    "preds = fit_model_cv(reviews, user_experience_level, SB_lm, cv = 10, scoring = 'accuracy')\n",
    "print(\"runtime:\\t\", time() - t0)\n",
    "print(preds)\n",
    "print(np.mean(preds))\n",
    "print(np.var(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for Baseline, NB and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VECTORIZER_TOKEN_PATTERN = u\"(?u)\\\\b\\\\w+\\\\b\"\n",
    "ngram_vectorizer = CountVectorizer(ngram_range=(1,3),\\\n",
    "                                        min_df=1,\\\n",
    "                                        max_df=1.0,\\\n",
    "                                        lowercase=True,\\\n",
    "                                        analyzer=\"word\",\\\n",
    "                                        token_pattern=VECTORIZER_TOKEN_PATTERN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "built_data_set = sklearn_helpers.build_data_set(curr_df,\n",
    "                                                vectorizer = ngram_vectorizer,\n",
    "                                                aspect_str = \"user_num_ratings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict user log ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model_cv(X, y, model, cv = 10, scoring = 'mean_squared_error'):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"    \n",
    "    scores = cross_val_score(model,\n",
    "                             X = X,\n",
    "                             y = y,\n",
    "                             scoring = scoring,\n",
    "                             cv = cv,\n",
    "                             n_jobs = -1)\n",
    "    return scores * -1 ## cross_val_score flips the sign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Tuning Ridge\n",
    "param_grid = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1]}\n",
    "ridge_search = GridSearchCV(ridge, param_grid, scoring=\"mean_squared_error\", cv=10, n_jobs=-1,\n",
    "                            pre_dispatch='2*n_jobs')\n",
    "ridge_search.fit(built_data_set['X'], built_data_set['y'])\n",
    "best_alpha = ridge_search.best_params_['alpha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime:\t 11.3086550236\n",
      "results:\t [ 0.16618698  0.17540324  0.16622791  0.17081001  0.16771507  0.15280705\n",
      "  0.1683629   0.16585258  0.15763097  0.16212557]\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=best_alpha)\n",
    "\n",
    "start_time = time()\n",
    "res = fit_model_cv(built_data_set['X'], built_data_set['y'], ridge)\n",
    "run_time = time() - start_time\n",
    "print(\"runtime:\\t\", run_time)\n",
    "print(\"results:\\t\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime:\t 34.3513929844\n",
      "results:\t [ 0.79278528  0.83662492  0.81684246  0.82282741  0.80772041  0.79014939\n",
      "  0.78796325  0.81053297  0.77854169  0.79399241]\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.1)\n",
    "\n",
    "start_time = time()\n",
    "res = fit_model_cv(built_data_set['X'], built_data_set['y'], lasso)\n",
    "run_time = time() - start_time\n",
    "print(\"runtime:\\t\", run_time)\n",
    "print(\"results:\\t\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime:\t 1455.33228302\n",
      "results:\t [ 0.63688272  0.61744725]\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestRegressor(n_estimators=100,\n",
    "                                      max_features=\"sqrt\",\n",
    "                                      n_jobs=-1)\n",
    "start_time = time()\n",
    "res = fit_model_cv(built_data_set['X'], built_data_set['y'], random_forest, cv=2)\n",
    "run_time = time() - start_time\n",
    "print(\"runtime:\\t\", run_time)\n",
    "print(\"results:\\t\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Regressor (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime:\t 6.90261101723\n",
      "results:\t [ 0.79278528  0.83662492  0.81684246  0.82282741  0.80772041  0.79014939\n",
      "  0.78796325  0.81053297  0.77854169  0.79399241]\n"
     ]
    }
   ],
   "source": [
    "baseline = DummyRegressor()\n",
    "\n",
    "start_time = time()\n",
    "res = fit_model_cv(built_data_set['X'], built_data_set['y'], baseline)\n",
    "run_time = time() - start_time\n",
    "print(\"runtime:\\t\", run_time)\n",
    "print(\"results:\\t\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Multinomial_NB = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = fit_model_cv(built_data_set['X'], built_data_set['y'], Multinomial_NB, cv = 10, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.59813396  0.58713762  0.57514162  0.5838054   0.57333333  0.577\n",
      "  0.60566667  0.56418806  0.57352451  0.58772515]\n",
      "0.582565631476\n",
      "0.00014158957577\n"
     ]
    }
   ],
   "source": [
    "print(preds)\n",
    "print(np.mean(preds))\n",
    "print(np.var(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseline = LanguageModelClassifier.BaselineLanguageModel()\n",
    "preds = fit_model_cv(reviews, user_experience_level, baseline, cv = 10, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.253666694857\n",
      "7.15250628363e-09\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(preds))\n",
    "print(np.var(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime:\t 7200.27582192\n",
      "[ 0.63457695  0.64145285  0.63366667  0.64        0.641       0.63366667\n",
      "  0.64133333  0.63754585  0.65188396  0.63087696]\n",
      "0.638600323334\n",
      "3.25410581082e-05\n"
     ]
    }
   ],
   "source": [
    "## runtime ~408sec with n_estimators=100, number-of-observations=full set\n",
    "## ~359sec with n_estimators=500, 20,000 observations (0.32326767)\n",
    "## runtim ~ 7200sec with n_estimators = 100, number-of-observations = 30000, score = 0.638600323334\n",
    "\n",
    "rf_classifier = RandomForestClassifier(max_features='log2', n_estimators=100, n_jobs=-1)\n",
    "t0 = time()\n",
    "preds = fit_model_cv(built_data_set['X'], built_data_set['y'], rf_classifier, cv = 10, scoring = 'accuracy')\n",
    "print(\"runtime:\\t\", time() - t0)\n",
    "print(preds)\n",
    "print(np.mean(preds))\n",
    "print(np.var(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_data = [('random_forest', 'max_features=log2;n_estimators=100', 'sample_size=30000', p) for p in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('random_forest',\n",
       "  'max_features=log2;n_estimators=100',\n",
       "  'sample_size=30000',\n",
       "  0.63457694870086612),\n",
       " ('random_forest',\n",
       "  'max_features=log2;n_estimators=100',\n",
       "  'sample_size=30000',\n",
       "  0.64145284905031652),\n",
       " ('random_forest',\n",
       "  'max_features=log2;n_estimators=100',\n",
       "  'sample_size=30000',\n",
       "  0.63366666666666671),\n",
       " ('random_forest',\n",
       "  'max_features=log2;n_estimators=100',\n",
       "  'sample_size=30000',\n",
       "  0.64000000000000001),\n",
       " ('random_forest',\n",
       "  'max_features=log2;n_estimators=100',\n",
       "  'sample_size=30000',\n",
       "  0.64100000000000001),\n",
       " ('random_forest',\n",
       "  'max_features=log2;n_estimators=100',\n",
       "  'sample_size=30000',\n",
       "  0.63366666666666671),\n",
       " ('random_forest',\n",
       "  'max_features=log2;n_estimators=100',\n",
       "  'sample_size=30000',\n",
       "  0.64133333333333331),\n",
       " ('random_forest',\n",
       "  'max_features=log2;n_estimators=100',\n",
       "  'sample_size=30000',\n",
       "  0.63754584861620545),\n",
       " ('random_forest',\n",
       "  'max_features=log2;n_estimators=100',\n",
       "  'sample_size=30000',\n",
       "  0.65188396132044013),\n",
       " ('random_forest',\n",
       "  'max_features=log2;n_estimators=100',\n",
       "  'sample_size=30000',\n",
       "  0.63087695898632878)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = 'analysis_data/rf_cv10_' + str(date.fromtimestamp(time())) + '.csv'\n",
    "import csv\n",
    "with open(path, \"w\") as f:\n",
    "    csv.register_dialect(\"custom\", delimiter=\",\", skipinitialspace=True)\n",
    "    writer = csv.writer(f, dialect=\"custom\")\n",
    "    for tup in rf_data:\n",
    "        writer.writerow(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2016-05-20'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "date.today()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user_num_ratings'].quantile(q = [0.25, 0.5, 0.75]).values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# review[df.loc[(df['user_num_ratings'] > 75) & (df['user_num_ratings'] < 276), :]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "# print(\"Performing grid search...\")\n",
    "# print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "# print(\"parameters:\")\n",
    "# pprint(parameters)\n",
    "# t0 = time()\n",
    "# grid_search.fit(data.data, data.target)\n",
    "# print(\"done in %0.3fs\" % (time() - t0))\n",
    "# print()\n",
    "\n",
    "# print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "# print(\"Best parameters set:\")\n",
    "# best_parameters = grid_search.best_estimator_.get_params()\n",
    "# for param_name in sorted(parameters.keys()):\n",
    "#     print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
