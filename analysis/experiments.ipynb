{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Experiments__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import time\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = '../data/clean_data_full.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num observations:\t52778\n"
     ]
    }
   ],
   "source": [
    "## Num rows\n",
    "print \"num observations:\\t\", len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unigram_phi(review):\n",
    "    return Counter(review.split())\n",
    "def bigram_phi(review):\n",
    "    return Counter(nltk.bigrams(review.split()))\n",
    "def unigram_bigram_phi(review):\n",
    "    return unigram_phi(review) + bigram_phi(review)\n",
    "def trigram_phi(review):\n",
    "    return Counter(nltk.trigrams(review.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Baseline:\n",
    "    def __init__(self):\n",
    "        self.avg_respsponse = 0\n",
    "    def fit(self, X, y):\n",
    "        self.avg_response = np.mean(y)\n",
    "    def predict(self, X):\n",
    "        rows, _ = X.shape\n",
    "        return np.repeat(self.avg_response, rows)\n",
    "\n",
    "def fit_baseline(X, y):\n",
    "    \"\"\"\n",
    "    Naive baseline return mean training prediction\n",
    "    \"\"\"\n",
    "    mod = Baseline()\n",
    "    mod.fit(X, y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_linear_regression(X, y):    \n",
    "    \"\"\"\n",
    "    Linear Regression\n",
    "    \"\"\"\n",
    "    mod = LinearRegression(fit_intercept=True, n_jobs = -1)\n",
    "    mod.fit(X, y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_lasso(X, y, alpha = 0.1, max_iter = 1000):\n",
    "    lasso = Lasso(alpha = alpha, max_iter = max_iter)\n",
    "    mod = lasso.fit(X, y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_ridge(X, y, alpha = 0.1, max_iter = 1000):\n",
    "    lasso = Lasso(alpha = alpha, max_iter = max_iter)\n",
    "    mod = lasso.fit(X, y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_gbm_regression(X, y,\n",
    "                       n_estimators = 100,\n",
    "                       learning_rate = 0.1,\n",
    "                       max_depth = 1,\n",
    "                       random_state = 0,\n",
    "                       loss = \"ls\"):\n",
    "    \"\"\"\n",
    "    Gradient Boosting Method Regression\n",
    "    \"\"\"\n",
    "    gbm = GradientBoostingRegressor(n_estimators = n_estimators,\n",
    "                                    learning_rate = learning_rate,\n",
    "                                    max_depth = max_depth,\n",
    "                                    random_state = random_state,\n",
    "                                    loss = \"ls\")\n",
    "    mod = gbm.fit(X.toarray(), y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_rf_regression(X, y,\n",
    "                      n_estimators = 100,\n",
    "                      max_depth = math.sqrt,\n",
    "                      max_features = 'auto',\n",
    "                      n_jobs = -1):\n",
    "    \"\"\"\n",
    "    Gradient Boosting Method Regression\n",
    "    \"\"\"\n",
    "    ## Restrict depth with fn if None is not passed\n",
    "    ## expect somthing like sqrt() to be passed here\n",
    "    max_depth = max_depth(X.shape[1]) if max_depth != None else max_depth\n",
    "    rf = RandomForestRegressor(n_estimators = n_estimators,\n",
    "                               max_depth = max_depth,\n",
    "                               max_features = max_features,\n",
    "                               n_jobs = n_jobs)\n",
    "    mod = rf.fit(X.toarray(), y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_adaBoost_regression(X, y,\n",
    "                            n_estimators = 50,\n",
    "                            learning_rate = 1,\n",
    "                            loss = \"linear\"):\n",
    "    \"\"\"\n",
    "    Gradient Boosting Method Regression\n",
    "    \"\"\"\n",
    "    adaBoost = AdaBoostRegressor(n_estimators = n_estimators,\n",
    "                           learning_rate = learning_rate,\n",
    "                           loss = loss)\n",
    "    mod = adaBoost.fit(X.toarray(), y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_data_set(data, vectorizer = None, aspect_str = \"OVERALL\"):\n",
    "    \"\"\"\n",
    "    Aspect ratings cols:\n",
    "        (7)  review_palate_score      -- score_normalizer = 1\n",
    "        (8)  review_taste_score       -- score_normalizer = 2\n",
    "        (11) review_aroma_score       -- score_normalizer = 2\n",
    "        (14) review_avg_score         -- score_normalizer = 1\n",
    "        (18) review_overall_score     -- score_normalizer = 4\n",
    "        (20) review_appearance_score  -- score_normalizer = 1\n",
    "        \n",
    "    predict_col :: column for aspect we're predicting, current default is column 18 (OVERALL)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ## RateBeer scrape data locations\n",
    "    ## ------------------------------\n",
    "    REVIEW_BLOB = 24\n",
    "    ASPECTS = {\n",
    "        \"PALATE\"     : [7, 1],\n",
    "        \"TASTE\"      : [8, 2],\n",
    "        \"AROMA\"      : [11, 2],\n",
    "        \"AVERAGE\"    : [14, 1],\n",
    "        \"OVERALL\"    : [18, 4],\n",
    "        \"APPEARANCE\" : [20, 1]\n",
    "    }\n",
    "    assert aspect_str in ASPECTS\n",
    "        \n",
    "    aspect_column = ASPECTS[aspect_str][0]      ## Get aspect rating column\n",
    "    aspect_normalizer = ASPECTS[aspect_str][1]  ## Get aspect normalizer\n",
    "    labels = []                                 ## Ratings\n",
    "    feat_dicts = []                             ## Features\n",
    "    raw_examples = []                           ## Review strings\n",
    "    data_values = data.values                   ## Data from pandas df\n",
    "    for row in data.values:\n",
    "        review, score = row[REVIEW_BLOB], row[aspect_column]\n",
    "        score = float(score) / aspect_normalizer\n",
    "\n",
    "        ## Safety check\n",
    "        if not isinstance(review, basestring):\n",
    "            print 'weird review:\\t', review\n",
    "            \n",
    "#         feat_dicts.append(phi(review))\n",
    "        labels.append(score)\n",
    "        raw_examples.append(review)\n",
    "        \n",
    "    # In training, we want a new vectorizer:\n",
    "    if vectorizer == None:\n",
    "        vectorizer = DictVectorizer(sparse=True)\n",
    "        feat_matrix = vectorizer.fit_transform(feat_dicts)\n",
    "    # In assessment, we featurize using the existing vectorizer:\n",
    "    else:\n",
    "        feat_matrix = vectorizer.fit_transform(raw_examples)\n",
    "\n",
    "    return {'X'            : feat_matrix, \n",
    "            'y'            : labels, \n",
    "            'vectorizer'   : vectorizer, \n",
    "            'raw_examples' : raw_examples,\n",
    "            'feature_names' : vectorizer.get_feature_names()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def experiment(data,\n",
    "               model = fit_baseline,\n",
    "               phi = None,\n",
    "               assess_data = None,\n",
    "               train_size = 0.9,\n",
    "               score_metric = mean_squared_error,\n",
    "               verbose = False):\n",
    "    ## Check that we're running a model\n",
    "    assert(model != None)\n",
    "    \n",
    "    ## Timing\n",
    "    start_time = time.time()\n",
    "    \n",
    "    ## Build data set\n",
    "    X_train = data['X'] \n",
    "    y_train = data['y']\n",
    "    vectorizer = data['vectorizer']\n",
    "    feature_names = data['feature_names']\n",
    "\n",
    "    ## Test-train split\n",
    "    if assess_data == None:\n",
    "        X_train, X_assess, y_train, y_assess = train_test_split(\n",
    "                X_train, y_train, train_size = train_size)\n",
    "    ## Only use for test-set\n",
    "    else:\n",
    "        assess = build_data_set(assess_data, phi, vectorizer = vectorizer)\n",
    "        X_assess, y_assess = assess['X'], assess['y']\n",
    "        \n",
    "\n",
    "    ## Model data\n",
    "    mod = model(X_train, y_train)\n",
    "    predictions = mod.predict(X_assess.toarray())\n",
    "    \n",
    "    ## Timing\n",
    "    run_time = time.time() - start_time\n",
    "\n",
    "    if verbose:\n",
    "        print \"\\tExperiment information\"\n",
    "        print '\\t======================='\n",
    "        print \"\\ttrained:\\t\", model.__name__\n",
    "        print \"\\tnum training observations:\\t\", X_train.shape[0]\n",
    "        print \"\\tnum training features:\\t\", X_train.shape[1]\n",
    "        print \"\\tscore_metric:\\t\", score_metric.__name__\n",
    "        print \"\\trun time: \", run_time\n",
    "#         if model.__name__ == 'fit_linear_regression' or\\\n",
    "#             model.__name__ == 'fit_lasso' or\\\n",
    "#             model.__name__ == 'fit_ridge':\n",
    "# #             print feature_names[1:10]\n",
    "# #             print mod.coef_[1]\n",
    "        print \"y_assess[1:10]:\\t\", y_assess[1:10]\n",
    "        print \"predictions[1:10]:\\t\", predictions[1:10]\n",
    "    \n",
    "    ## Return results dict - will write to csv\n",
    "    res = {\n",
    "        \"score\"        : score_metric(y_assess, predictions),\n",
    "        \"score_name\"   : score_metric.__name__,\n",
    "        \"predictions\"  : predictions,\n",
    "        \"y_assess\"     : y_assess\n",
    "    }\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_reader(train_path = data_path, n = 1000):\n",
    "    df = pd.read_csv(data_path)\n",
    "    return df.sample(n)\n",
    "\n",
    "def dev_reader(test_path, n = 100):\n",
    "    df = pd.read_csv(data_path)\n",
    "    return df.sample(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizer's encode phi..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## bigram_vectorizer\n",
    "## -----------------\n",
    "## normalization:\n",
    "##  * lower\n",
    "##  * remove stop words\n",
    "##  * min word length == 2\n",
    "##\n",
    "bigram_vectorizer = CountVectorizer(analyzer='word', stop_words = 'english', ngram_range=(2, 2), min_df = 3, max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## unigram_vectorizer\n",
    "## -----------------\n",
    "## normalization:\n",
    "##  * lower\n",
    "##  * remove stop words\n",
    "##  * min word length == 2\n",
    "##\n",
    "unigram_vectorizer = CountVectorizer(analyzer='word', stop_words = 'english', ngram_range=(1, 1), min_df = 3, max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## trigram_vectorizer\n",
    "## ------------------\n",
    "## normalization:\n",
    "##  * lower\n",
    "##  * remove stop words\n",
    "##  * min word length == 2\n",
    "##\n",
    "trigram_vectorizer = CountVectorizer(analyzer='word', stop_words = 'english', ngram_range=(3, 3), min_df = 3, max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def set_vectorizer(n_gram = \"unigram\",\n",
    "                   min_df = 3,\n",
    "                   sample_size = 10000,\n",
    "                   stop_words = 'english',\n",
    "                   features_prop = 0.25,\n",
    "                   max_features = 2000):\n",
    "\n",
    "    max_features = int(sample_size * features_prop) if max_features == None else max_features\n",
    "    if n_gram == \"trigram\":\n",
    "        ngram_range = (3,3)\n",
    "    elif n_gram == \"bigram\":\n",
    "        ngram_range = (2,2)\n",
    "    else: # default to unigram\n",
    "        ngram_range = (1,1)\n",
    "    \n",
    "    return CountVectorizer(analyzer='word',\n",
    "                           ngram_range = ngram_range,\n",
    "                           min_df = min_df,\n",
    "                           max_features = max_features,\n",
    "                           stop_words = stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def build_data_set(data, phi, vectorizer = None, aspect_str = \"OVERALL\"):\n",
    "\n",
    "n_samples = 40000\n",
    "vectorizer = set_vectorizer(n_gram = \"unigram\", sample_size = n_samples, features_prop = 0.05, max_features = None)\n",
    "train_d = train_reader(data_path, n = n_samples)\n",
    "built_data_set = build_data_set(train_d, vectorizer = vectorizer, aspect_str = 'TASTE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prelim runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tExperiment information\n",
      "\t=======================\n",
      "\ttrained:\tfit_baseline\n",
      "\tnum training observations:\t36000\n",
      "\tnum training features:\t2000\n",
      "\tscore_metric:\tmean_squared_error\n",
      "\trun time:  0.0844750404358\n",
      "y_assess[1:10]:\t[4.0, 3.5, 3.5, 3.5, 2.5, 3.0, 5.0, 4.5, 1.0]\n",
      "predictions[1:10]:\t[ 3.40823611  3.40823611  3.40823611  3.40823611  3.40823611  3.40823611\n",
      "  3.40823611  3.40823611  3.40823611]\n",
      "-----------------------------\n",
      "mean_squared_error\n",
      "0.954698024498\n"
     ]
    }
   ],
   "source": [
    "baseline_results = experiment(data = built_data_set,\n",
    "           model = fit_baseline,\n",
    "           verbose = True,\n",
    "           score_metric = mean_squared_error)\n",
    "print \"-----------------------------\"\n",
    "print baseline_results['score_name']\n",
    "print baseline_results['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regresssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tExperiment information\n",
      "\t=======================\n",
      "\ttrained:\tfit_linear_regression\n",
      "\tnum training observations:\t9000\n",
      "\tnum training features:\t500\n",
      "\tscore_metric:\tmean_squared_error\n",
      "\trun time:  0.0764510631561\n",
      "[u'12', u'12oz', u'2015', u'2016', u'absolutely', u'abv', u'acidic', u'actually', u'aftertaste']\n",
      "0.0975684074743\n",
      "y_assess[1:10]:\t[4.0, 5.0, 3.0, 3.5, 4.0, 3.0, 1.5, 2.0, 3.5]\n",
      "predictions[1:10]:\t[ 3.65662724  3.49659209  3.06649112  3.5858353   3.965771    3.56893541\n",
      "  2.83095575  3.58264942  2.94071635]\n",
      "-----------------------------\n",
      "mean_squared_error\n",
      "0.703292786185\n"
     ]
    }
   ],
   "source": [
    "## Note: running time ~ 1 minute @ 40k observations\n",
    "## Note on number of features :: lookes like LM with n = 40,000 obs prefers 1,200 features\n",
    "lm_results = experiment(data = built_data_set,\n",
    "           model = fit_linear_regression,\n",
    "           verbose = True,\n",
    "           score_metric = mean_squared_error)\n",
    "print \"-----------------------------\"\n",
    "print lm_results['score_name']\n",
    "print lm_results['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n_samples = 20000\n",
    "# vectorizer = set_vectorizer(n_gram = \"unigram\", sample_size = n_samples, features_prop = 1, max_features = None)\n",
    "# train_d = train_reader(data_path, n = n_samples)\n",
    "# built_data_set = build_data_set(train_d, vectorizer = vectorizer, aspect_str = 'TASTE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tExperiment information\n",
      "\t=======================\n",
      "\ttrained:\tfit_ridge\n",
      "\tnum training observations:\t36000\n",
      "\tnum training features:\t2000\n",
      "\tscore_metric:\tmean_squared_error\n",
      "\trun time:  0.227540016174\n",
      "[u'03', u'04', u'05', u'06', u'07', u'08', u'09', u'10', u'100']\n",
      "0.0\n",
      "y_assess[1:10]:\t[3.5, 4.5, 3.5, 3.5, 4.0, 2.5, 4.0, 3.5, 4.0]\n",
      "predictions[1:10]:\t[ 3.40380556  3.40380556  3.40380556  3.40380556  3.40380556  3.40380556\n",
      "  3.40380556  3.40380556  3.40380556]\n",
      "-----------------------------\n",
      "mean_squared_error\n",
      "0.913640537809\n"
     ]
    }
   ],
   "source": [
    "## Note: running time few seconds @ 40k observations\n",
    "ridge_results = experiment(data = built_data_set,\n",
    "           model = fit_ridge,\n",
    "           verbose = True, \n",
    "           score_metric = mean_squared_error)\n",
    "print \"-----------------------------\"\n",
    "print ridge_results['score_name']\n",
    "print ridge_results['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tExperiment information\n",
      "\t=======================\n",
      "\ttrained:\tfit_lasso\n",
      "\tnum training observations:\t36000\n",
      "\tnum training features:\t2000\n",
      "\tscore_metric:\tmean_squared_error\n",
      "\trun time:  0.223304986954\n",
      "[u'03', u'04', u'05', u'06', u'07', u'08', u'09', u'10', u'100']\n",
      "0.0\n",
      "y_assess[1:10]:\t[4.0, 5.0, 4.0, 4.0, 3.5, 3.5, 4.0, 3.0, 3.5]\n",
      "predictions[1:10]:\t[ 3.40316667  3.40316667  3.40316667  3.40316667  3.40316667  3.40316667\n",
      "  3.40316667  3.40316667  3.40316667]\n",
      "-----------------------------\n",
      "mean_squared_error\n",
      "0.887641277778\n"
     ]
    }
   ],
   "source": [
    "## Note: running time few seconds @ 40k observations\n",
    "lasso_results = experiment(data = built_data_set,\n",
    "           model = fit_lasso,\n",
    "           verbose = True,\n",
    "           score_metric = mean_squared_error)\n",
    "print \"-----------------------------\"\n",
    "print lasso_results['score_name']\n",
    "print lasso_results['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-bf088b1a60c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m            \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_rf_regression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m            \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m            score_metric = mean_squared_error)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"-----------------------------\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mrf_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-85-022802735a1b>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(data, model, phi, assess_data, train_size, score_metric, verbose)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_assess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_assess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_assess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-141-d07dbe865683>\u001b[0m in \u001b[0;36mfit_rf_regression\u001b[0;34m(X, y, n_estimators, max_depth, max_features, n_jobs)\u001b[0m\n\u001b[1;32m     14\u001b[0m                                \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                n_jobs = n_jobs)\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benpeloquin/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    271\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 273\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benpeloquin/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    664\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benpeloquin/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benpeloquin/anaconda2/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benpeloquin/anaconda2/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benpeloquin/anaconda2/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Note: run time ~3min with 10K obs and 10 trees\n",
    "##                ~8min with 40K obs and 0.05 * 40K (2000)features and 10 trees\n",
    "##                ~\n",
    "rf_results = experiment(data = built_data_set,\n",
    "           model = fit_rf_regression,\n",
    "           verbose = True,\n",
    "           score_metric = mean_squared_error)\n",
    "print \"-----------------------------\"\n",
    "print rf_results['score_name']\n",
    "print rf_results['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tExperiment information\n",
      "\t=======================\n",
      "\ttrained:\tfit_gbm_regression\n",
      "\tnum training observations:\t36000\n",
      "\tnum training features:\t1200\n",
      "\tscore_metrics:\t['mean_squared_error', 'r2_score']\n",
      "\trun time:  117.637772083\n",
      "y_assess[1:10]:\t[4.5, 4.0, 4.0, 4.5, 4.0, 3.0, 4.5, 5.0, 2.0]\n",
      "predictions[1:10]:\t[ 3.6650699   3.34262176  3.47430726  3.47430726  3.59508346  3.09653888\n",
      "  3.67842892  3.55909983  3.39723603]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7754653792740176, 0.15726864684880737]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def fit_gbm_regression(X, y,\n",
    "#                        n_estimators = 10,\n",
    "#                        learning_rate = 0.1,\n",
    "#                        max_depth = 1,\n",
    "#                        random_state = 0,\n",
    "#                        loss = \"ls\"):\n",
    "\n",
    "# Note: running time is currently ver long\n",
    "experiment(data = built_data_set,\n",
    "           model = fit_gbm_regression,\n",
    "           verbose = True,\n",
    "           score_metrics = [mean_squared_error, r2_score])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Note: running time is currently ver long\n",
    "experiment(data = built_data_set,\n",
    "           model = fit_adaBoost_regression,\n",
    "           verbose = True,\n",
    "           score_metric = mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tune_learner_params(X, y, basemod, cv, param_grid, scoring = None): \n",
    "    \"\"\"\n",
    "    Description\n",
    "        \n",
    "    \"\"\"    \n",
    "    # Find the best model within param_grid:\n",
    "    crossvalidator = GridSearchCV(basemod, param_grid, cv = cv, scoring=scoring, n_jobs = -1)\n",
    "    crossvalidator.fit(X, y)\n",
    "    # Report some information:\n",
    "    print(\"Best params\", crossvalidator.best_params_)\n",
    "    print(\"Best score: %0.03f\" % crossvalidator.best_score_)\n",
    "\n",
    "    return crossvalidator.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_lasso_cv(X, y):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"    \n",
    "    basemod = Lasso()\n",
    "    cv = 5\n",
    "    param_grid = {\n",
    "        'alpha': [0.01, 0.05, 0.1, 0.2, 0.5], \n",
    "        'max_iter': [2, 10, 25, 50, 500]\n",
    "                 }    \n",
    "    return tune_learner_params(X, y, basemod, cv, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best params', {'alpha': 0.01, 'max_iter': 2})\n",
      "Best score: 0.124\n",
      "\tExperiment information\n",
      "\t=======================\n",
      "\ttrained:\tfit_lasso_cv\n",
      "\tnum training observations:\t36000\n",
      "\tnum training features:\t2000\n",
      "\tscore_metric:\tmean_squared_error\n",
      "\trun time:  32.2567131519\n",
      "y_assess[1:10]:\t[4.0, 3.5, 4.5, 5.0, 4.0, 1.5, 2.0, 1.5, 5.0]\n",
      "predictions[1:10]:\t[ 3.70219408  3.36351796  3.29294267  3.45679579  3.58465853  3.01585312\n",
      "  3.29294267  3.36194337  3.45460068]\n"
     ]
    }
   ],
   "source": [
    "lasso_cv_res = experiment(data = built_data_set,\n",
    "                          model = fit_lasso_cv,\n",
    "                          verbose = True,\n",
    "                          score_metric = mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.839102674598\n"
     ]
    }
   ],
   "source": [
    "print lasso_cv_res['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_rf_cv(X, y):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"    \n",
    "    basemod = RandomForestRegressor()\n",
    "    cv = 5\n",
    "    param_grid = {\n",
    "        'n_estimators': [1, 10, 100], \n",
    "        'max_features': [1, 'sqrt', 'log2', 'auto']\n",
    "                 }    \n",
    "    return tune_learner_params(X, y, basemod, cv, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_cv_res = experiment(data = built_data_set,\n",
    "                          model = fit_rf_cv,\n",
    "                          verbose = True,\n",
    "                          score_metric = mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune num features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tune_max_features(n_observations = 10000,\n",
    "                      n_gram = \"unigram\",\n",
    "                      tuning_values = [0.05, 0.10, 0.2, 0.3],\n",
    "                      model = fit_rf_regression,\n",
    "                      score_metric = mean_squared_error,\n",
    "                      verbose = False):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    res = defaultdict(float)\n",
    "    for tuning_value in tuning_values:\n",
    "        if verbose:\n",
    "            print \"Currently tuning:\\t\", model.__name__\n",
    "            print \"n_gram:\\t\", n_gram\n",
    "            print \"tuning_value:\\t\", tuning_value\n",
    "            \n",
    "        vectorizer = set_vectorizer(n_gram = n_gram,\n",
    "                                sample_size = n_observations,\n",
    "                                features_prop = tuning_value)\n",
    "        train_d = train_reader(data_path, n = n_samples)\n",
    "        built_data_set = build_data_set(train_d, vectorizer = vectorizer, aspect_str = 'TASTE')\n",
    "        res[str(tuning_value)] = experiment(data = built_data_set,\n",
    "                                            model = model,\n",
    "                                            verbose = False,\n",
    "                                            score_metrics = [mean_squared_error])\n",
    "\n",
    "    run_time = time.time() - start_time    \n",
    "    print \"runtime for \" + str(n_observations) + \":\\t\", run_time\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently tuning:\tfit_rf_regression\n",
      "n_gram:\tunigram\n",
      "tuning_value:\t0.05\n",
      "Currently tuning:\tfit_rf_regression\n",
      "n_gram:\tunigram\n",
      "tuning_value:\t0.1\n",
      "Currently tuning:\tfit_rf_regression\n",
      "n_gram:\tunigram\n",
      "tuning_value:\t0.2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-077f12cee8a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# n = 10000, alpha = 0.2, mse = 0.63\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtune_max_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_observations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_gram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"unigram\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-7573bdcb12ec>\u001b[0m in \u001b[0;36mtune_max_features\u001b[0;34m(n_observations, n_gram, tuning_values, model, score_metric, verbose)\u001b[0m\n\u001b[1;32m     23\u001b[0m                                             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                                             \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                                             score_metrics = [mean_squared_error])\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mrun_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-f127219379f7>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(data, model, phi, assess_data, train_size, score_metrics, verbose)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_assess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_assess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_assess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-b3effafa3e36>\u001b[0m in \u001b[0;36mfit_rf_regression\u001b[0;34m(X, y, n_estimators, max_depth, max_features, n_jobs)\u001b[0m\n\u001b[1;32m     11\u001b[0m                                \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                n_jobs = n_jobs)\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benpeloquin/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    271\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 273\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benpeloquin/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    664\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benpeloquin/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benpeloquin/anaconda2/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benpeloquin/anaconda2/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benpeloquin/anaconda2/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Records\n",
    "# n = 5000; runtime = 235sec; best 0.3 (0.69)\n",
    "# n = 2000; runtime = 60sec\n",
    "# n = 10000, alpha = 0.2, mse = 0.63\n",
    "\n",
    "tune_max_features(n_observations = 10000, n_gram = \"unigram\", verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Between aspects - lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ngram = 'bigram'\n",
    "ASPECTS = ['OVERALL', 'TASTE', 'AROMA', 'PALATE', 'APPEARANCE']\n",
    "for aspect in ASPECTS:\n",
    "    n_samples = 40000\n",
    "    vectorizer = set_vectorizer(n_gram = ngram, sample_size = n_samples)\n",
    "    train_d = train_reader(data_path, n = n_samples)\n",
    "    built_data_set = build_data_set(train_d, vectorizer = vectorizer, aspect_str = aspect)\n",
    "\n",
    "    print \"\\n-----------------\"\n",
    "    print \"ngram:\\t\", ngram\n",
    "    print \"curr aspect:\\t\", aspect\n",
    "    mse = experiment(data = built_data_set,\n",
    "           model = fit_lasso,\n",
    "           verbose = True)\n",
    "    print \"mse:\\t\", mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learners = [fit_linear_regression, fit_lasso, fit_gbm_regression]\n",
    "vectorizers = [unigram_vectorizer, bigram_vectorizer]\n",
    "vectorizer_names = [\"unigram\", \"bigram\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================\n",
      "Fitting:\tfit_linear_regression\n",
      "-------\n",
      "vectorizer:\tunigram\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-5bf7d8440306>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                          \u001b[0munigram_phi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                          \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                          verbose = True)\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"mse:\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-118-4f8ebdd3f064>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(train_data, model, phi, assess_data, train_size, score_metric, vectorizer, verbose)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m## Build data set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_data_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-117-98a8b234f812>\u001b[0m in \u001b[0;36mbuild_data_set\u001b[0;34m(data, phi, vectorizer)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# In assessment, we featurize using the existing vectorizer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mfeat_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     return {'X': feat_matrix, \n",
      "\u001b[0;32m/Users/benpeloquin/anaconda2/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 804\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benpeloquin/anaconda2/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m                     \u001b[0mj_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benpeloquin/anaconda2/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyzer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'char_wb'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             return lambda doc: self._char_wb_ngrams(\n\u001b[0;32m--> 229\u001b[0;31m                 preprocess(self.decode(doc)))\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyzer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'word'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benpeloquin/anaconda2/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m_char_wb_ngrams\u001b[0;34m(self, text_document)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mw_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0moffset\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                     \u001b[0mngrams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# count a short word (w_len < n) only once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for learner in learners:\n",
    "    print \"\\n=============================\"\n",
    "    print \"Fitting:\\t\", learner.__name__\n",
    "    for vectorizer, name in zip(vectorizers, vectorizer_names):\n",
    "        print \"-------\"\n",
    "        print \"vectorizer:\\t\", name\n",
    "        mse = experiment(train_d,\n",
    "                         learner,\n",
    "                         unigram_phi,\n",
    "                         vectorizer = vectorizer,\n",
    "                         verbose = True)\n",
    "        print \"mse:\\t\", mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_model(d_sample, model, phi, n_samples = 100):\n",
    "    res = [experiment(data, model, phi) for _ in range(n_samples)]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glm_res = run_model(train, fit_linear_regression, trigram_phi)\n",
    "gbm_res = run_model(train, fit_gbm_regression, trigram_phi)\n",
    "lasso_res = run_model(train, fit_lasso, trigram_phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm: 5.09104430619 1.65291139452\n",
      "gbm: 5.4193393923 2.1477179012\n",
      "lasso 5.5710284521 1.65857267327\n"
     ]
    }
   ],
   "source": [
    "print \"glm:\", np.mean(glm_res), np.var(glm_res)\n",
    "print \"gbm:\", np.mean(gbm_res), np.var(gbm_res)\n",
    "print \"lasso\", np.mean(lasso_res), np.var(lasso_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0933661297989\n",
      "0.0212407456292\n",
      "0.5025560931\n"
     ]
    }
   ],
   "source": [
    "print scipy.stats.wilcoxon(glm_res, gbm_res)[1]\n",
    "print scipy.stats.wilcoxon(glm_res, lasso_res)[1]\n",
    "print scipy.stats.wilcoxon(gbm_res, lasso_res)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
