{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Experiments__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import time\n",
    "from collections import Counter, defaultdict\n",
    "import scipy.stats\n",
    "import sklearn\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path = '../data/clean_data_full.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num observations:\t52778\n"
     ]
    }
   ],
   "source": [
    "## Num rows\n",
    "print \"num observations:\\t\", len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unigram_phi(review):\n",
    "    return Counter(review.split())\n",
    "def bigram_phi(review):\n",
    "    return Counter(nltk.bigrams(review.split()))\n",
    "def unigram_bigram_phi(review):\n",
    "    return unigram_phi(review) + bigram_phi(review)\n",
    "def trigram_phi(review):\n",
    "    return Counter(nltk.trigrams(review.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Baseline:\n",
    "    def __init__(self):\n",
    "        self.avg_respsponse = 0\n",
    "    def fit(self, X, y):\n",
    "        self.avg_response = np.mean(y)\n",
    "    def predict(self, X):\n",
    "        rows, _ = X.shape\n",
    "        return np.repeat(self.avg_response, rows)\n",
    "\n",
    "def fit_baseline(X, y):\n",
    "    \"\"\"\n",
    "    Naive baseline return mean training prediction\n",
    "    \"\"\"\n",
    "    mod = Baseline()\n",
    "    mod.fit(X, y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_linear_regression(X, y):    \n",
    "    \"\"\"\n",
    "    Linear Regression\n",
    "    \"\"\"\n",
    "    mod = LinearRegression(fit_intercept=True, n_jobs = -1)\n",
    "    mod.fit(X, y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_lasso(X, y, alpha = 0.1, max_iter = 1000):\n",
    "    lasso = Lasso(alpha = alpha, max_iter = max_iter)\n",
    "    mod = lasso.fit(X, y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_ridge(X, y, alpha = 0.1, max_iter = 1000):\n",
    "    lasso = Lasso(alpha = alpha, max_iter = max_iter)\n",
    "    mod = lasso.fit(X, y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_gbm_regression(X, y,\n",
    "                       n_estimators = 100,\n",
    "                       learning_rate = 0.1,\n",
    "                       max_depth = 1,\n",
    "                       random_state = 0,\n",
    "                       loss = \"ls\"):\n",
    "    \"\"\"\n",
    "    Gradient Boosting Method Regression\n",
    "    \"\"\"\n",
    "    gbm = GradientBoostingRegressor(n_estimators = n_estimators,\n",
    "                                    learning_rate = learning_rate,\n",
    "                                    max_depth = max_depth,\n",
    "                                    random_state = random_state,\n",
    "                                    loss = \"ls\")\n",
    "    mod = gbm.fit(X.toarray(), y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_rf_regression(X, y,\n",
    "                      n_estimators = 100,\n",
    "                      max_depth = math.sqrt,\n",
    "                      max_features = 'auto',\n",
    "                      n_jobs = -1):\n",
    "    \"\"\"\n",
    "    Gradient Boosting Method Regression\n",
    "    \"\"\"\n",
    "    ## Restrict depth with fn if None is not passed\n",
    "    ## expect somthing like sqrt() to be passed here\n",
    "    max_depth = max_depth(X.shape[1]) if max_depth != None else max_depth\n",
    "    rf = RandomForestRegressor(n_estimators = n_estimators,\n",
    "                               max_depth = max_depth,\n",
    "                               max_features = max_features,\n",
    "                               n_jobs = n_jobs)\n",
    "    mod = rf.fit(X.toarray(), y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_adaBoost_regression(X, y,\n",
    "                            n_estimators = 50,\n",
    "                            learning_rate = 1,\n",
    "                            loss = \"linear\"):\n",
    "    \"\"\"\n",
    "    Gradient Boosting Method Regression\n",
    "    \"\"\"\n",
    "    adaBoost = AdaBoostRegressor(n_estimators = n_estimators,\n",
    "                           learning_rate = learning_rate,\n",
    "                           loss = loss)\n",
    "    mod = adaBoost.fit(X.toarray(), y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_data_set(data, vectorizer = None, aspect_str = \"OVERALL\"):\n",
    "    \"\"\"\n",
    "    Aspect ratings cols:\n",
    "        (7)  review_palate_score      -- score_normalizer = 1\n",
    "        (8)  review_taste_score       -- score_normalizer = 2\n",
    "        (11) review_aroma_score       -- score_normalizer = 2\n",
    "        (14) review_avg_score         -- score_normalizer = 1\n",
    "        (18) review_overall_score     -- score_normalizer = 4\n",
    "        (20) review_appearance_score  -- score_normalizer = 1\n",
    "        \n",
    "    predict_col :: column for aspect we're predicting, current default is column 18 (OVERALL)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ## RateBeer scrape data locations\n",
    "    ## ------------------------------\n",
    "    REVIEW_BLOB = 24\n",
    "    ASPECTS = {\n",
    "        \"PALATE\"     : [7, 1],\n",
    "        \"TASTE\"      : [8, 2],\n",
    "        \"AROMA\"      : [11, 2],\n",
    "        \"AVERAGE\"    : [14, 1],\n",
    "        \"OVERALL\"    : [18, 4],\n",
    "        \"APPEARANCE\" : [20, 1]\n",
    "    }\n",
    "    assert aspect_str in ASPECTS\n",
    "        \n",
    "    aspect_column = ASPECTS[aspect_str][0]      ## Get aspect rating column\n",
    "    aspect_normalizer = ASPECTS[aspect_str][1]  ## Get aspect normalizer\n",
    "    labels = []                                 ## Ratings\n",
    "    feat_dicts = []                             ## Features\n",
    "    raw_examples = []                           ## Review strings\n",
    "    data_values = data.values                   ## Data from pandas df\n",
    "    for row in data.values:\n",
    "        review, score = row[REVIEW_BLOB], row[aspect_column]\n",
    "        score = float(score) / aspect_normalizer\n",
    "\n",
    "        ## Safety check\n",
    "        if not isinstance(review, basestring):\n",
    "            print 'weird review:\\t', review\n",
    "            \n",
    "#         feat_dicts.append(phi(review))\n",
    "        labels.append(score)\n",
    "        raw_examples.append(review)\n",
    "        \n",
    "    # In training, we want a new vectorizer:\n",
    "    if vectorizer == None:\n",
    "        vectorizer = DictVectorizer(sparse=True)\n",
    "        feat_matrix = vectorizer.fit_transform(feat_dicts)\n",
    "    # In assessment, we featurize using the existing vectorizer:\n",
    "    else:\n",
    "        feat_matrix = vectorizer.fit_transform(raw_examples)\n",
    "\n",
    "    return {'X'            : feat_matrix, \n",
    "            'y'            : labels, \n",
    "            'vectorizer'   : vectorizer, \n",
    "            'raw_examples' : raw_examples,\n",
    "            'feature_names' : vectorizer.get_feature_names()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def experiment(data,\n",
    "               model = fit_baseline,\n",
    "               phi = None,\n",
    "               assess_data = None,\n",
    "               train_size = 0.9,\n",
    "               score_metric = mean_squared_error,\n",
    "               verbose = False):\n",
    "    ## Check that we're running a model\n",
    "    assert(model != None)\n",
    "    \n",
    "    ## Timing\n",
    "    start_time = time.time()\n",
    "    \n",
    "    ## Build data set\n",
    "    X_train = data['X'] \n",
    "    y_train = data['y']\n",
    "    vectorizer = data['vectorizer']\n",
    "    feature_names = data['feature_names']\n",
    "\n",
    "    ## Test-train split\n",
    "    if assess_data == None:\n",
    "        X_train, X_assess, y_train, y_assess = train_test_split(\n",
    "                X_train, y_train, train_size = train_size)\n",
    "    ## Only use for test-set\n",
    "    else:\n",
    "        assess = build_data_set(assess_data, phi, vectorizer = vectorizer)\n",
    "        X_assess, y_assess = assess['X'], assess['y']\n",
    "        \n",
    "\n",
    "    ## Model data\n",
    "    mod = model(X_train, y_train)\n",
    "    predictions = mod.predict(X_assess.toarray())\n",
    "    \n",
    "    ## Timing\n",
    "    run_time = time.time() - start_time\n",
    "\n",
    "    if verbose:\n",
    "        print \"\\tExperiment information\"\n",
    "        print '\\t======================='\n",
    "        print \"\\ttrained:\\t\", model.__name__\n",
    "        print \"\\tnum training observations:\\t\", X_train.shape[0]\n",
    "        print \"\\tnum training features:\\t\", X_train.shape[1]\n",
    "        print \"\\tscore_metric:\\t\", score_metric.__name__\n",
    "        print \"\\trun time: \", run_time\n",
    "#         if model.__name__ == 'fit_linear_regression' or\\\n",
    "#             model.__name__ == 'fit_lasso' or\\\n",
    "#             model.__name__ == 'fit_ridge':\n",
    "# #             print feature_names[1:10]\n",
    "# #             print mod.coef_[1]\n",
    "        print \"y_assess[1:10]:\\t\", y_assess[1:10]\n",
    "        print \"predictions[1:10]:\\t\", predictions[1:10]\n",
    "    \n",
    "    ## Return results dict - will write to csv\n",
    "    res = {\n",
    "        \"score\"        : score_metric(y_assess, predictions),\n",
    "        \"score_name\"   : score_metric.__name__,\n",
    "        \"predictions\"  : predictions,\n",
    "        \"y_assess\"     : y_assess\n",
    "    }\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_reader(train_path = data_path, n = 1000):\n",
    "    df = pd.read_csv(data_path)\n",
    "    return df.sample(n)\n",
    "\n",
    "# def dev_reader(test_path, n = 100):\n",
    "#     df = pd.read_csv(data_path)\n",
    "#     return df.sample(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizer's encode phi..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## bigram_vectorizer\n",
    "## -----------------\n",
    "## normalization:\n",
    "##  * lower\n",
    "##  * remove stop words\n",
    "##  * min word length == 2\n",
    "##\n",
    "bigram_vectorizer = CountVectorizer(analyzer='word', stop_words = 'english', ngram_range=(2, 2), min_df = 3, max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## unigram_vectorizer\n",
    "## -----------------\n",
    "## normalization:\n",
    "##  * lower\n",
    "##  * remove stop words\n",
    "##  * min word length == 2\n",
    "##\n",
    "unigram_vectorizer = CountVectorizer(analyzer='word', stop_words = 'english', ngram_range=(1, 1), min_df = 3, max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## trigram_vectorizer\n",
    "## ------------------\n",
    "## normalization:\n",
    "##  * lower\n",
    "##  * remove stop words\n",
    "##  * min word length == 2\n",
    "##\n",
    "trigram_vectorizer = CountVectorizer(analyzer='word', stop_words = 'english', ngram_range=(3, 3), min_df = 3, max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def set_vectorizer(ngram_range = (1,1),\n",
    "                   min_df = 3,\n",
    "                   sample_size = 10000,\n",
    "                   stop_words = 'english',\n",
    "                   features_prop = 0.05,\n",
    "                   max_features = 2000,\n",
    "                   lowercase = True,\n",
    "                   binary = False):\n",
    "\n",
    "    max_features = int(sample_size * features_prop) if max_features == None else max_features\n",
    "    \n",
    "    return CountVectorizer(analyzer='word',\n",
    "                           ngram_range = ngram_range,\n",
    "                           min_df = min_df,\n",
    "                           max_features = max_features,\n",
    "                           stop_words = stop_words,\n",
    "                           binary = binary,\n",
    "                           lowercase = lowercase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def build_data_set(data, phi, vectorizer = None, aspect_str = \"OVERALL\"):\n",
    "\n",
    "n_samples = 40000\n",
    "vectorizer = set_vectorizer(n_gram = \"unigram\", sample_size = n_samples, features_prop = 0.05, max_features = None)\n",
    "train_d = data_reader(data_path, n = n_samples)\n",
    "built_data_set = build_data_set(train_d, vectorizer = vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prelim runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tExperiment information\n",
      "\t=======================\n",
      "\ttrained:\tfit_baseline\n",
      "\tnum training observations:\t9000\n",
      "\tnum training features:\t500\n",
      "\tscore_metric:\tmean_squared_error\n",
      "\trun time:  0.00888109207153\n",
      "y_assess[1:10]:\t[5.0, 3.25, 2.5, 3.5, 4.0, 3.5, 3.0, 3.0, 3.75]\n",
      "predictions[1:10]:\t[ 3.45480556  3.45480556  3.45480556  3.45480556  3.45480556  3.45480556\n",
      "  3.45480556  3.45480556  3.45480556]\n",
      "-----------------------------\n",
      "mean_squared_error\n",
      "0.887323857253\n"
     ]
    }
   ],
   "source": [
    "baseline_results = experiment(data = built_data_set,\n",
    "           model = fit_baseline,\n",
    "           verbose = True,\n",
    "           score_metric = mean_squared_error)\n",
    "print \"-----------------------------\"\n",
    "print baseline_results['score_name']\n",
    "print baseline_results['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regresssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tExperiment information\n",
      "\t=======================\n",
      "\ttrained:\tfit_linear_regression\n",
      "\tnum training observations:\t36000\n",
      "\tnum training features:\t2000\n",
      "\tscore_metric:\tmean_squared_error\n",
      "\trun time:  0.69296002388\n",
      "y_assess[1:10]:\t[4.0, 5.0, 4.5, 3.75, 3.25, 4.25, 4.75, 4.5, 4.5]\n",
      "predictions[1:10]:\t[ 4.10252529  3.39662777  3.59958548  3.54214488  3.47564997  3.27873549\n",
      "  3.77199107  3.58033956  3.94887898]\n",
      "-----------------------------\n",
      "mean_squared_error\n",
      "0.678707950421\n"
     ]
    }
   ],
   "source": [
    "## Note: running time ~ 1 minute @ 40k observations\n",
    "## Note on number of features :: lookes like LM with n = 40,000 obs prefers 1,200 features\n",
    "lm_results = experiment(data = built_data_set,\n",
    "           model = fit_linear_regression,\n",
    "           verbose = True,\n",
    "           score_metric = mean_squared_error)\n",
    "print \"-----------------------------\"\n",
    "print lm_results['score_name']\n",
    "print lm_results['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n_samples = 20000\n",
    "# vectorizer = set_vectorizer(n_gram = \"unigram\", sample_size = n_samples, features_prop = 1, max_features = None)\n",
    "# train_d = train_reader(data_path, n = n_samples)\n",
    "# built_data_set = build_data_set(train_d, vectorizer = vectorizer, aspect_str = 'TASTE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tExperiment information\n",
      "\t=======================\n",
      "\ttrained:\tfit_ridge\n",
      "\tnum training observations:\t9000\n",
      "\tnum training features:\t6374\n",
      "\tscore_metric:\tmean_squared_error\n",
      "\trun time:  0.178368806839\n",
      "y_assess[1:10]:\t[4.0, 4.25, 4.0, 3.5, 4.25, 4.25, 2.5, 2.5, 4.0]\n",
      "predictions[1:10]:\t[ 3.47438889  3.47438889  3.47438889  3.47438889  3.47438889  3.47438889\n",
      "  3.47438889  3.47438889  3.47438889]\n",
      "-----------------------------\n",
      "mean_squared_error\n",
      "0.940097873457\n"
     ]
    }
   ],
   "source": [
    "## Note: running time few seconds @ 40k observations\n",
    "ridge_results = experiment(data = built_data_set,\n",
    "           model = fit_ridge,\n",
    "           verbose = True, \n",
    "           score_metric = mean_squared_error)\n",
    "print \"-----------------------------\"\n",
    "print ridge_results['score_name']\n",
    "print ridge_results['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tExperiment information\n",
      "\t=======================\n",
      "\ttrained:\tfit_lasso\n",
      "\tnum training observations:\t9000\n",
      "\tnum training features:\t6374\n",
      "\tscore_metric:\tmean_squared_error\n",
      "\trun time:  0.138798952103\n",
      "y_assess[1:10]:\t[4.5, 3.75, 4.25, 3.0, 3.75, 0.25, 4.0, 1.25, 3.25]\n",
      "predictions[1:10]:\t[ 3.47011111  3.47011111  3.47011111  3.47011111  3.47011111  3.47011111\n",
      "  3.47011111  3.47011111  3.47011111]\n",
      "-----------------------------\n",
      "mean_squared_error\n",
      "1.02048034568\n"
     ]
    }
   ],
   "source": [
    "## Note: running time few seconds @ 40k observations\n",
    "lasso_results = experiment(data = built_data_set,\n",
    "           model = fit_lasso,\n",
    "           verbose = True,\n",
    "           score_metric = mean_squared_error)\n",
    "print \"-----------------------------\"\n",
    "print lasso_results['score_name']\n",
    "print lasso_results['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Note: run time ~3min with 10K obs and 10 trees\n",
    "##                ~8min with 40K obs and 0.05 * 40K (2000)features and 10 trees\n",
    "##                ~\n",
    "rf_results = experiment(data = built_data_set,\n",
    "           model = fit_rf_regression,\n",
    "           verbose = True,\n",
    "           score_metric = mean_squared_error)\n",
    "print \"-----------------------------\"\n",
    "print rf_results['score_name']\n",
    "print rf_results['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def fit_gbm_regression(X, y,\n",
    "#                        n_estimators = 10,\n",
    "#                        learning_rate = 0.1,\n",
    "#                        max_depth = 1,\n",
    "#                        random_state = 0,\n",
    "#                        loss = \"ls\"):\n",
    "\n",
    "# Note: running time is currently ver long\n",
    "experiment(data = built_data_set,\n",
    "           model = fit_gbm_regression,\n",
    "           verbose = True,\n",
    "           score_metric = mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Note: running time is currently ver long\n",
    "experiment(data = built_data_set,\n",
    "           model = fit_adaBoost_regression,\n",
    "           verbose = True,\n",
    "           score_metric = mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tune_learner_params(X, y, basemod, cv, param_grid, scoring = None): \n",
    "    \"\"\"\n",
    "    Description\n",
    "        \n",
    "    \"\"\"    \n",
    "    # Find the best model within param_grid:\n",
    "    crossvalidator = GridSearchCV(basemod, param_grid, cv = cv, scoring=scoring, n_jobs = -1)\n",
    "    crossvalidator.fit(X, y)\n",
    "    # Report some information:\n",
    "    print(\"All results\", crossvalidator.grid_scores_)\n",
    "    print(\"Best params\", crossvalidator.best_params_)\n",
    "    print(\"Best score: %0.03f\" % crossvalidator.best_score_)\n",
    "\n",
    "    return crossvalidator.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_lasso_cv(X, y):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"    \n",
    "    basemod = Lasso()\n",
    "    cv = 2\n",
    "    param_grid = {\n",
    "        'alpha': [0.01, 0.05, 0.1, 0.2, 0.5], \n",
    "        'max_iter': [2, 10, 25, 50, 500]\n",
    "                 }    \n",
    "    return tune_learner_params(X, y, basemod, cv, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('All results', [mean: 0.12776, std: 0.00227, params: {'alpha': 0.01, 'max_iter': 2}, mean: 0.12659, std: 0.00218, params: {'alpha': 0.01, 'max_iter': 10}, mean: 0.12659, std: 0.00218, params: {'alpha': 0.01, 'max_iter': 25}, mean: 0.12659, std: 0.00218, params: {'alpha': 0.01, 'max_iter': 50}, mean: 0.12659, std: 0.00218, params: {'alpha': 0.01, 'max_iter': 500}, mean: 0.01084, std: 0.00108, params: {'alpha': 0.05, 'max_iter': 2}, mean: 0.01079, std: 0.00111, params: {'alpha': 0.05, 'max_iter': 10}, mean: 0.01079, std: 0.00111, params: {'alpha': 0.05, 'max_iter': 25}, mean: 0.01079, std: 0.00111, params: {'alpha': 0.05, 'max_iter': 50}, mean: 0.01079, std: 0.00111, params: {'alpha': 0.05, 'max_iter': 500}, mean: -0.00000, std: 0.00000, params: {'alpha': 0.1, 'max_iter': 2}, mean: -0.00000, std: 0.00000, params: {'alpha': 0.1, 'max_iter': 10}, mean: -0.00000, std: 0.00000, params: {'alpha': 0.1, 'max_iter': 25}, mean: -0.00000, std: 0.00000, params: {'alpha': 0.1, 'max_iter': 50}, mean: -0.00000, std: 0.00000, params: {'alpha': 0.1, 'max_iter': 500}, mean: -0.00000, std: 0.00000, params: {'alpha': 0.2, 'max_iter': 2}, mean: -0.00000, std: 0.00000, params: {'alpha': 0.2, 'max_iter': 10}, mean: -0.00000, std: 0.00000, params: {'alpha': 0.2, 'max_iter': 25}, mean: -0.00000, std: 0.00000, params: {'alpha': 0.2, 'max_iter': 50}, mean: -0.00000, std: 0.00000, params: {'alpha': 0.2, 'max_iter': 500}, mean: -0.00000, std: 0.00000, params: {'alpha': 0.5, 'max_iter': 2}, mean: -0.00000, std: 0.00000, params: {'alpha': 0.5, 'max_iter': 10}, mean: -0.00000, std: 0.00000, params: {'alpha': 0.5, 'max_iter': 25}, mean: -0.00000, std: 0.00000, params: {'alpha': 0.5, 'max_iter': 50}, mean: -0.00000, std: 0.00000, params: {'alpha': 0.5, 'max_iter': 500}])\n",
      "('Best params', {'alpha': 0.01, 'max_iter': 2})\n",
      "Best score: 0.128\n",
      "\tExperiment information\n",
      "\t=======================\n",
      "\ttrained:\tfit_lasso_cv\n",
      "\tnum training observations:\t9000\n",
      "\tnum training features:\t500\n",
      "\tscore_metric:\tmean_squared_error\n",
      "\trun time:  1.82914614677\n",
      "y_assess[1:10]:\t[4.5, 3.75, 3.75, 1.5, 3.25, 3.75, 3.75, 3.0, 3.25]\n",
      "predictions[1:10]:\t[ 3.62902576  4.35390684  3.42197783  3.0572066   4.06086381  3.30753477\n",
      "  3.54833677  3.32435782  3.38862294]\n"
     ]
    }
   ],
   "source": [
    "lasso_cv_res = experiment(data = built_data_set,\n",
    "                          model = fit_lasso_cv,\n",
    "                          verbose = True,\n",
    "                          score_metric = mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.915768392253\n"
     ]
    }
   ],
   "source": [
    "print lasso_cv_res['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_rf_cv(X, y):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"    \n",
    "    basemod = RandomForestRegressor()\n",
    "    cv = 2\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 500], \n",
    "        'max_features': ['log2']\n",
    "                 }    \n",
    "    return tune_learner_params(X, y, basemod, cv, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Note  :: got MSE of 0.68 with RF \n",
    "rf_cv_res = experiment(data = built_data_set,\n",
    "                          model = fit_rf_cv,\n",
    "                          verbose = True,\n",
    "                          score_metric = mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_cv_res['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune num features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tune_max_features(n_observations = 10000,\n",
    "                      n_gram = \"unigram\",\n",
    "                      tuning_values = [0.05, 0.10, 0.2, 0.3],\n",
    "                      model = fit_rf_regression,\n",
    "                      score_metric = mean_squared_error,\n",
    "                      verbose = False):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    res = defaultdict(float)\n",
    "    for tuning_value in tuning_values:\n",
    "        if verbose:\n",
    "            print \"Currently tuning:\\t\", model.__name__\n",
    "            print \"n_gram:\\t\", n_gram\n",
    "            print \"tuning_value:\\t\", tuning_value\n",
    "            \n",
    "        vectorizer = set_vectorizer(n_gram = n_gram,\n",
    "                                sample_size = n_observations,\n",
    "                                features_prop = tuning_value)\n",
    "        train_d = train_reader(data_path, n = n_samples)\n",
    "        built_data_set = build_data_set(train_d, vectorizer = vectorizer, aspect_str = 'TASTE')\n",
    "        res[str(tuning_value)] = experiment(data = built_data_set,\n",
    "                                            model = model,\n",
    "                                            verbose = False,\n",
    "                                            score_metrics = [mean_squared_error])\n",
    "\n",
    "    run_time = time.time() - start_time    \n",
    "    print \"runtime for \" + str(n_observations) + \":\\t\", run_time\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Records\n",
    "# n = 5000; runtime = 235sec; best 0.3 (0.69)\n",
    "# n = 2000; runtime = 60sec\n",
    "# n = 10000, alpha = 0.2, mse = 0.63\n",
    "\n",
    "# tune_max_features(n_observations = 10000, n_gram = \"unigram\", verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General cross-validated score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Data\n",
    "n_samples = 40000\n",
    "vectorizer = set_vectorizer(ngram_range = (1, 1),\n",
    "                            sample_size = n_samples,\n",
    "                            features_prop = 0.05,\n",
    "                            max_features = None,\n",
    "                            lowercase = True,\n",
    "                            binary = True)\n",
    "train_d = data_reader(data_path, n = n_samples)\n",
    "built_data_set = build_data_set(train_d, vectorizer = vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model_cv(X, y, model, cv = 10, scoring = 'mean_squared_error'):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"    \n",
    "    scores = cross_val_score(model,\n",
    "                             X = X,\n",
    "                             y = y,\n",
    "                             scoring = scoring,\n",
    "                             cv = cv,\n",
    "                             n_jobs = -1)\n",
    "    return scores * -1 ## cross_val_score flips the sign\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm_params = {\n",
    "    'n_estimators': 500,\n",
    "    'max_depth': 4,\n",
    "    'min_samples_split': 1,\n",
    "    'learning_rate': 0.01,\n",
    "    'loss': 'ls'\n",
    "}\n",
    "gbm_model = GradientBoostingRegressor(**gbm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_params = {\n",
    "    'n_estimators' : 500,\n",
    "    'max_features' : 'log2',\n",
    "    'n_jobs'       : -1\n",
    "}\n",
    "rf_model = RandomForestRegressor(**rf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0.661254254169\n",
      "var 0.000218697071569\n"
     ]
    }
   ],
   "source": [
    "lm_cv_res = fit_model_cv(built_data_set['X'], built_data_set['y'], model = lm_model, cv = 10)\n",
    "print 'mean', np.mean(lm_cv_res)\n",
    "print 'var', np.var(lm_cv_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:\t0.665621206226\n",
      "var:\t5.84956498855e-06\n",
      "runtime:\t186.072751999\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "rf_cv_res = fit_model_cv(built_data_set['X'], built_data_set['y'], model = rf_model, cv = 2)\n",
    "run_time = time.time() - start_time\n",
    "print 'mean:\\t', np.mean(rf_cv_res)\n",
    "print 'var:\\t', np.var(rf_cv_res)\n",
    "print 'runtime:\\t', run_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-366-4cdfea3f6a43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgbm_cv_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_model_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilt_data_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuilt_data_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgbm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgbm_cv_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'var'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgbm_cv_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-357-1602e5f41fa3>\u001b[0m in \u001b[0;36mfit_model_cv\u001b[0;34m(X, y, model, cv, scoring)\u001b[0m\n\u001b[1;32m      7\u001b[0m                              \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                              \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                              cv = cv)\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;31m## cross_val_score flips the sign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benpeloquin/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m   1359\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m                                               fit_params)\n\u001b[0;32m-> 1361\u001b[0;31m                       for train, test in cv)\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benpeloquin/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpre_dispatch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"all\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benpeloquin/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self, func, args, kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \"\"\"\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_verbosity_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benpeloquin/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, args, kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benpeloquin/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1459\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benpeloquin/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m--> 980\u001b[0;31m                                     begin_at_stage, monitor)\n\u001b[0m\u001b[1;32m    981\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benpeloquin/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1039\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m                                      random_state)\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benpeloquin/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, criterion, splitter, random_state)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m--> 766\u001b[0;31m                      check_input=False)\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benpeloquin/anaconda2/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    302\u001b[0m                                            max_leaf_nodes)\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "gbm_cv_res = fit_model_cv(built_data_set['X'].toarray(), built_data_set['y'], model = gbm_model, cv = 2)\n",
    "run_time = time.time() - start_time\n",
    "print 'mean:\\t', np.mean(gbm_cv_res)\n",
    "print 'var:\\t', np.var(gbm_cv_res)\n",
    "print 'runtime:\\t', run_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Between aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------\n",
      "ngram:\tunigram\n",
      "curr aspect:\tOVERALL\n",
      "\tExperiment information\n",
      "\t=======================\n",
      "\ttrained:\tfit_linear_regression\n",
      "\tnum training observations:\t36000\n",
      "\tnum training features:\t2000\n",
      "\tscore_metric:\tmean_squared_error\n",
      "\trun time:  0.698040962219\n",
      "y_assess[1:10]:\t[4.5, 4.25, 4.0, 0.25, 3.75, 4.75, 3.25, 3.25, 3.0]\n",
      "predictions[1:10]:\t[ 3.94613552  4.53600669  4.00284222  3.46959722  3.10406295  3.84065894\n",
      "  3.24267995  3.72572006  3.62688588]\n",
      "mse:\t0.635508621105\n",
      "\n",
      "-----------------\n",
      "ngram:\tunigram\n",
      "curr aspect:\tTASTE\n",
      "\tExperiment information\n",
      "\t=======================\n",
      "\ttrained:\tfit_linear_regression\n",
      "\tnum training observations:\t36000\n",
      "\tnum training features:\t2000\n",
      "\tscore_metric:\tmean_squared_error\n",
      "\trun time:  0.692892074585\n",
      "y_assess[1:10]:\t[4.25, 3.0, 3.25, 1.25, 3.5, 4.25, 5.0, 3.0, 1.75]\n",
      "predictions[1:10]:\t[ 4.10865449  3.33297045  3.09999102  1.28320703  3.3647986   4.60556742\n",
      "  3.95957174  3.75462826  3.42502059]\n",
      "mse:\t0.713278923193\n",
      "\n",
      "-----------------\n",
      "ngram:\tunigram\n",
      "curr aspect:\tAROMA\n",
      "\tExperiment information\n",
      "\t=======================\n",
      "\ttrained:\tfit_linear_regression\n",
      "\tnum training observations:\t36000\n",
      "\tnum training features:\t2000\n",
      "\tscore_metric:\tmean_squared_error\n",
      "\trun time:  0.770345926285\n",
      "y_assess[1:10]:\t[3.75, 3.25, 3.0, 4.75, 3.0, 3.25, 4.0, 3.25, 4.0]\n",
      "predictions[1:10]:\t[ 3.47776751  3.69442459  3.19862143  3.99804372  3.54974451  2.85730315\n",
      "  3.59177933  3.53489617  3.86546842]\n",
      "mse:\t0.645197525892\n",
      "\n",
      "-----------------\n",
      "ngram:\tunigram\n",
      "curr aspect:\tPALATE\n",
      "\tExperiment information\n",
      "\t=======================\n",
      "\ttrained:\tfit_linear_regression\n",
      "\tnum training observations:\t36000\n",
      "\tnum training features:\t2000\n",
      "\tscore_metric:\tmean_squared_error\n",
      "\trun time:  0.701984167099\n",
      "y_assess[1:10]:\t[4.5, 3.5, 4.0, 4.0, 3.25, 3.0, 3.5, 3.0, 3.75]\n",
      "predictions[1:10]:\t[ 4.15641817  3.13588267  3.27358157  3.77780319  2.90279078  3.45910309\n",
      "  3.39002236  3.61581904  3.34339794]\n",
      "mse:\t0.660478156848\n",
      "\n",
      "-----------------\n",
      "ngram:\tunigram\n",
      "curr aspect:\tAPPEARANCE\n",
      "\tExperiment information\n",
      "\t=======================\n",
      "\ttrained:\tfit_linear_regression\n",
      "\tnum training observations:\t36000\n",
      "\tnum training features:\t2000\n",
      "\tscore_metric:\tmean_squared_error\n",
      "\trun time:  0.67693901062\n",
      "y_assess[1:10]:\t[5.0, 2.5, 4.5, 3.5, 3.5, 4.25, 3.75, 4.5, 3.75]\n",
      "predictions[1:10]:\t[ 4.38736943  3.5828378   3.80283789  3.49973072  2.86203252  4.28536378\n",
      "  3.21708735  3.55651934  3.79556813]\n",
      "mse:\t0.687417112775\n"
     ]
    }
   ],
   "source": [
    "ngram = 'unigram'\n",
    "ASPECTS = ['OVERALL', 'TASTE', 'AROMA', 'PALATE', 'APPEARANCE']\n",
    "for aspect in ASPECTS:    \n",
    "    n_samples = 40000\n",
    "    vectorizer = set_vectorizer(n_gram = ngram, sample_size = n_samples, features_prop = 0.05, max_features = None)\n",
    "    train_d = data_reader(data_path, n = n_samples)\n",
    "    built_data_set = build_data_set(train_d, vectorizer = vectorizer)\n",
    "    print \"\\n-----------------\"\n",
    "    print \"ngram:\\t\", ngram\n",
    "    print \"curr aspect:\\t\", aspect\n",
    "    \n",
    "    # Current model\n",
    "    results = experiment(data = built_data_set,\n",
    "                         model = fit_linear_regression,\n",
    "                         verbose = True,\n",
    "                         score_metric = mean_squared_error)\n",
    "    print \"mse:\\t\", results['score']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learners = [fit_linear_regression, fit_lasso, fit_gbm_regression]\n",
    "vectorizers = [unigram_vectorizer, bigram_vectorizer]\n",
    "vectorizer_names = [\"unigram\", \"bigram\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================\n",
      "Fitting:\tfit_linear_regression\n",
      "-------\n",
      "vectorizer:\tunigram\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-5bf7d8440306>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                          \u001b[0munigram_phi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                          \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                          verbose = True)\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"mse:\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-118-4f8ebdd3f064>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(train_data, model, phi, assess_data, train_size, score_metric, vectorizer, verbose)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m## Build data set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_data_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-117-98a8b234f812>\u001b[0m in \u001b[0;36mbuild_data_set\u001b[0;34m(data, phi, vectorizer)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# In assessment, we featurize using the existing vectorizer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mfeat_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     return {'X': feat_matrix, \n",
      "\u001b[0;32m/Users/benpeloquin/anaconda2/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 804\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benpeloquin/anaconda2/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m                     \u001b[0mj_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benpeloquin/anaconda2/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyzer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'char_wb'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             return lambda doc: self._char_wb_ngrams(\n\u001b[0;32m--> 229\u001b[0;31m                 preprocess(self.decode(doc)))\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyzer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'word'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/benpeloquin/anaconda2/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m_char_wb_ngrams\u001b[0;34m(self, text_document)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mw_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0moffset\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                     \u001b[0mngrams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# count a short word (w_len < n) only once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for learner in learners:\n",
    "    print \"\\n=============================\"\n",
    "    print \"Fitting:\\t\", learner.__name__\n",
    "    for vectorizer, name in zip(vectorizers, vectorizer_names):\n",
    "        print \"-------\"\n",
    "        print \"vectorizer:\\t\", name\n",
    "        mse = experiment(train_d,\n",
    "                         learner,\n",
    "                         unigram_phi,\n",
    "                         vectorizer = vectorizer,\n",
    "                         verbose = True)\n",
    "        print \"mse:\\t\", mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_model(d_sample, model, phi, n_samples = 100):\n",
    "    res = [experiment(data, model, phi) for _ in range(n_samples)]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glm_res = run_model(train, fit_linear_regression, trigram_phi)\n",
    "gbm_res = run_model(train, fit_gbm_regression, trigram_phi)\n",
    "lasso_res = run_model(train, fit_lasso, trigram_phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm: 5.09104430619 1.65291139452\n",
      "gbm: 5.4193393923 2.1477179012\n",
      "lasso 5.5710284521 1.65857267327\n"
     ]
    }
   ],
   "source": [
    "print \"glm:\", np.mean(glm_res), np.var(glm_res)\n",
    "print \"gbm:\", np.mean(gbm_res), np.var(gbm_res)\n",
    "print \"lasso\", np.mean(lasso_res), np.var(lasso_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0933661297989\n",
      "0.0212407456292\n",
      "0.5025560931\n"
     ]
    }
   ],
   "source": [
    "print scipy.stats.wilcoxon(glm_res, gbm_res)[1]\n",
    "print scipy.stats.wilcoxon(glm_res, lasso_res)[1]\n",
    "print scipy.stats.wilcoxon(gbm_res, lasso_res)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
